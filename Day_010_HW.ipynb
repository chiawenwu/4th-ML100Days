import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression

data_path = 'data/'
df_train = pd.read_csv(data_path + 'house_train.csv.gz')
train_Y = np.log1p(df_train['SalePrice'])
df = df_train.drop(['Id','SalePrice'],axis=1)
df.head()
num_features =[]
for dtype,feature in zip(df.dtypes,df.columns):
  if dtype == 'float64' or dtype == 'int64':
    num_features.append(feature)
print(f'{len(num_features)} Numeric Features : {num_features}\n')

df = df[num_features]
df = df.fillna(-1)
MMEncoder = MinMaxScaler()
train_num = train_Y.shape[0]
df.head()
import seaborn as sns
import matplotlib.pyplot as plt
sns.regplot(x = df['1stFlrSF'][:train_num], y=train_Y)
plt.show()

train_X = MMEncoder.fit_transform(df)
estimator = LinearRegression()
cross_val_score(estimator,train_X,train_Y,cv=5).mean()
df['1stFlrSF'].describe()

df['1stFlrSF']=df['1stFlrSF'].clip(882,1391)
sns.regplot(x=df['1stFlrSF'],y=train_Y)
plt.show()
train_X = MMEncoder.fit_transform(df)
estimator = LinearRegression()
cross_val_score(estimator,train_X,train_Y,cv=5).mean()

keep_indexs= (df['1stFlrSF']>882) & (df['1stFlrSF']<1391)
df = df[keep_indexs]
train_Y = train_Y[keep_indexs]
sns.regplot(x =df['1stFlrSF'],y=train_Y)
plt.show()

train_X = MMEncoder.fit_transform(df)
estimator = LinearRegression()
cross_val_score(estimator,train_X,train_Y,cv=5).mean()

"""
限制上下限>25% <75%的分數只是微微提高分數
捨棄離群值的方法提高0.02,結果是比較好的
調整離群值因為離群值被修改失真故並無法提高較好的分數
反之捨棄離群值因為捨比較異常的數字保留原始資料,並無失真
故提高分數


"""
